{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shwu/prayog/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL = \"sarvamai/OpenHathi-7B-Hi-v0.1-Base\"\n",
    "DATASET = \"sarvamai/samvaad-hi-v1\"\n",
    "\n",
    "# paths\n",
    "CUSTOM_DATA = Path(\"custom_data\")\n",
    "\n",
    "MODELS = CUSTOM_DATA / \"models\"\n",
    "DATA = CUSTOM_DATA / \"datasets\"\n",
    "\n",
    "MODEL_PATH = MODELS / \"openhathi\"\n",
    "DATA_PATH = DATA / \"samvaad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: sarvamai/OpenHathi-7B-Hi-v0.1-Base\n",
      "DATASET: sarvamai/samvaad-hi-v1\n",
      "CUSTOM_DATA: /home/shwu/prayog/custom_data\n",
      "MODELS: /home/shwu/prayog/custom_data/models\n",
      "DATA: /home/shwu/prayog/custom_data/datasets\n",
      "MODEL_PATH: /home/shwu/prayog/custom_data/models/openhathi\n",
      "DATA_PATH: /home/shwu/prayog/custom_data/datasets/samvaad\n"
     ]
    }
   ],
   "source": [
    "print(f\"MODEL: {MODEL}\")\n",
    "print(f\"DATASET: {DATASET}\")\n",
    "print(f\"CUSTOM_DATA: {CUSTOM_DATA.absolute()}\")\n",
    "print(f\"MODELS: {MODELS.absolute()}\")\n",
    "print(f\"DATA: {DATA.absolute()}\")\n",
    "print(f\"MODEL_PATH: {MODEL_PATH.absolute()}\")\n",
    "print(f\"DATA_PATH: {DATA_PATH.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Explore and format dataset for usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['messages'],\n",
       "        num_rows: 101476\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = load_dataset(DATASET); ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_dict = []\n",
    "\n",
    "for messages in ds[\"train\"][\"messages\"]:\n",
    "    convo_stats = {}\n",
    "    for message in messages:\n",
    "        convo_stats[message[\"role\"]] = convo_stats.get(message[\"role\"], 0) + 1\n",
    "    role_dict.append(convo_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(role_dict)\n",
    "\n",
    "# Calculating mean, min, and max conversation exchanges between user and assistant\n",
    "user_mean = df['user'].mean()\n",
    "user_min = df['user'].min()\n",
    "user_max = df['user'].max()\n",
    "\n",
    "assistant_mean = df['assistant'].mean()\n",
    "assistant_min = df['assistant'].min()\n",
    "assistant_max = df['assistant'].max()\n",
    "\n",
    "# Plotting\n",
    "labels = ['User', 'Assistant']\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.2  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "\n",
    "# colors - https://coolors.co/palette/dad7cd-a3b18a-588157-3a5a40-344e41\n",
    "bars_mean = ax.bar(x - width, [user_mean, assistant_mean], width, label='mean', color='#DAD7CD')\n",
    "bars_min = ax.bar(x, [user_min, assistant_min], width, label='min', color='#A3B18A')\n",
    "bars_max = ax.bar(x + width, [user_max, assistant_max], width, label='max', color='#588157')\n",
    "\n",
    "ax.set_ylabel('conversation count')\n",
    "# ax.set_title('mean, min, and max conversation counts between User and Assistant')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare DataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepare two datasets for testing purposes; One following the tulu format and the other follows alpaca format (both are chat/instruction formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT = \"chat\"\n",
    "TULU = \"tulu\"\n",
    "EOL = \"\\n\"\n",
    "SPACE = \" \"\n",
    "\n",
    "ROLE_TOS = {\n",
    "    CHAT: {\n",
    "        \"user\": f\"user:{SPACE}\",\n",
    "        \"system\": f\"system:{SPACE}\",\n",
    "        \"assistant\": f\"assistant:{SPACE}\",\n",
    "    },\n",
    "    TULU: {\n",
    "        \"user\": f\"<|user|>{EOL}\",\n",
    "        \"system\": f\"<|system|>{EOL}\",\n",
    "        \"assistant\": f\"<|assistant|>{EOL}\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# 1. Tulu format\n",
    "# Adapted from AI4Bharat/IndicInstruct - https://github.com/AI4Bharat/IndicInstruct/blob/0d22aa33f6322d917bb83876e5fa877fb9edb2f2/eval/templates.py#L1\n",
    "\n",
    "def create_prompt_with_tulu_chat_format(messages, bos=\"<s>\", eos=\"</s>\", add_bos=True):\n",
    "    formatted_text = \"\"\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            formatted_text += ROLE_TOS[TULU][message[\"role\"]] + message[\"content\"] + EOL\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            formatted_text += ROLE_TOS[TULU][message[\"role\"]] + message[\"content\"] + EOL\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            formatted_text += ROLE_TOS[TULU][message[\"role\"]] + \\\n",
    "                message[\"content\"].strip() + eos + EOL\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Tulu chat template only supports 'system', 'user' and 'assistant' roles. Invalid role: {}.\".format(\n",
    "                    message[\"role\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    formatted_text = bos + formatted_text if add_bos else formatted_text\n",
    "    return formatted_text\n",
    "\n",
    "# 2. Chat format\n",
    "\n",
    "def create_prompt_with_chat_format(messages):\n",
    "    formatted_text = \"\"\n",
    "    for message in messages:\n",
    "        if message[\"role\"] in { \"system\", \"user\", \"assistant\"}:\n",
    "            formatted_text += ROLE_TOS[CHAT][message[\"role\"]] + message[\"content\"] + EOL\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Alpaca template only supports 'system', 'user' and 'assistant' roles. Invalid role: {}.\".format(\n",
    "                    message[\"role\"]\n",
    "                )\n",
    "            )\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_funcs = [\n",
    "    (CHAT, lambda ds_row: {\n",
    "        \"text\": create_prompt_with_chat_format(messages=ds_row[\"messages\"])\n",
    "    }), \n",
    "    (TULU, lambda ds_row: {\n",
    "        \"text\": create_prompt_with_tulu_chat_format(messages=ds_row[\"messages\"])\n",
    "    })\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push to hub\n",
    "    \n",
    "for (f_name, func) in map_funcs:\n",
    "    ds = ds = load_dataset(DATASET)\n",
    "    ds[\"train\"] = ds[\"train\"].map(func)\n",
    "    ds.push_to_hub(f\"shwubham/samvaad-hi-v1-{f_name}-format\")\n",
    "\n",
    "    for sample in ds[\"train\"][\"text\"][-2:]:\n",
    "        print(sample)\n",
    "        print(\"=\" * 100, \"\\n\")\n",
    "    \n",
    "    # save dataset\n",
    "    ds.save_to_disk(DATA_PATH / f_name)\n",
    "\n",
    "    del ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>challenge</th>\n",
       "      <th>model</th>\n",
       "      <th>shot</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.267626</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.312277</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.309358</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.256374</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arc-easy-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.264310</td>\n",
       "      <td>0.255433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arc-easy-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.291246</td>\n",
       "      <td>0.152862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arc-easy-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.275253</td>\n",
       "      <td>0.128456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>arc-easy-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.253788</td>\n",
       "      <td>0.227074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mmlu-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.248052</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mmlu-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.267179</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mmlu-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.282562</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mmlu-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.248558</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>indicsentiment</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.572144</td>\n",
       "      <td>0.236136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>indicsentiment</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.812625</td>\n",
       "      <td>0.769420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>indicsentiment</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.553106</td>\n",
       "      <td>0.688112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>indicsentiment</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.511022</td>\n",
       "      <td>0.016129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>winogrande</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.496448</td>\n",
       "      <td>0.347721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>winogrande</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.498027</td>\n",
       "      <td>0.494421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.247660</td>\n",
       "      <td>0.099783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.265385</td>\n",
       "      <td>0.145365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.265385</td>\n",
       "      <td>0.145365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hellaswag</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.247660</td>\n",
       "      <td>0.099783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arc-easy</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.313973</td>\n",
       "      <td>0.180325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>arc-easy</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.218348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arc-easy</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.255471</td>\n",
       "      <td>0.097614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>arc-easy</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.250421</td>\n",
       "      <td>0.221121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>arc-challenge-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.269625</td>\n",
       "      <td>0.115558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>arc-challenge-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.290956</td>\n",
       "      <td>0.180217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>arc-challenge-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.266212</td>\n",
       "      <td>0.127336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>arc-challenge-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.261092</td>\n",
       "      <td>0.084548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>hellaswag-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.247959</td>\n",
       "      <td>0.101346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hellaswag-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.267576</td>\n",
       "      <td>0.161672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hellaswag-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.267576</td>\n",
       "      <td>0.161672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>hellaswag-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.247959</td>\n",
       "      <td>0.101346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>boolq-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.442202</td>\n",
       "      <td>0.526234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>boolq-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>0.549168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>boolq-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.378287</td>\n",
       "      <td>0.548724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>boolq-hi</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.377982</td>\n",
       "      <td>0.548401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>indiccopa</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.512249</td>\n",
       "      <td>0.661515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>indiccopa</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.492205</td>\n",
       "      <td>0.659701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>indiccopa</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.494432</td>\n",
       "      <td>0.661699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>indiccopa</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.496659</td>\n",
       "      <td>0.662687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>indicxparaphrase</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.602897</td>\n",
       "      <td>0.714747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>indicxparaphrase</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.721778</td>\n",
       "      <td>0.764283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>indicxparaphrase</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.501998</td>\n",
       "      <td>0.661919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>indicxparaphrase</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.497003</td>\n",
       "      <td>0.661057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>boolq</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.420795</td>\n",
       "      <td>0.539173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>boolq</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.378287</td>\n",
       "      <td>0.548924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>boolq</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.378287</td>\n",
       "      <td>0.548724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>boolq</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.378899</td>\n",
       "      <td>0.548767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>indicxnli</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.333533</td>\n",
       "      <td>0.167115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>indicxnli</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>indicxnli</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.333134</td>\n",
       "      <td>0.167039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>indicxnli</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.331337</td>\n",
       "      <td>0.224210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>arc-challenge</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>0.156770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>arc-challenge</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>0shot</td>\n",
       "      <td>0.317406</td>\n",
       "      <td>0.202435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>arc-challenge</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.260239</td>\n",
       "      <td>0.116684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>arc-challenge</td>\n",
       "      <td>OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...</td>\n",
       "      <td>5shot</td>\n",
       "      <td>0.261092</td>\n",
       "      <td>0.090591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           challenge                                              model  \\\n",
       "0               mmlu  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "1               mmlu  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "2               mmlu  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "3               mmlu  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "4        arc-easy-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "5        arc-easy-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "6        arc-easy-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "7        arc-easy-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "8            mmlu-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "9            mmlu-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "10           mmlu-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "11           mmlu-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "12    indicsentiment  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "13    indicsentiment  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "14    indicsentiment  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "15    indicsentiment  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "16        winogrande  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "17        winogrande  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "18         hellaswag  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "19         hellaswag  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "20         hellaswag  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "21         hellaswag  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "22          arc-easy  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "23          arc-easy  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "24          arc-easy  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "25          arc-easy  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "26  arc-challenge-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "27  arc-challenge-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "28  arc-challenge-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "29  arc-challenge-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "30      hellaswag-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "31      hellaswag-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "32      hellaswag-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "33      hellaswag-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "34          boolq-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "35          boolq-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "36          boolq-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "37          boolq-hi  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "38         indiccopa  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "39         indiccopa  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "40         indiccopa  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "41         indiccopa  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "42  indicxparaphrase  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "43  indicxparaphrase  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "44  indicxparaphrase  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "45  indicxparaphrase  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "46             boolq  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "47             boolq  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "48             boolq  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "49             boolq  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "50         indicxnli  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "51         indicxnli  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "52         indicxnli  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "53         indicxnli  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "54     arc-challenge  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "55     arc-challenge  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "56     arc-challenge  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-t...   \n",
       "57     arc-challenge  OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-c...   \n",
       "\n",
       "     shot  accuracy        f1  \n",
       "0   0shot  0.267626 -1.000000  \n",
       "1   0shot  0.312277 -1.000000  \n",
       "2   5shot  0.309358 -1.000000  \n",
       "3   5shot  0.256374 -1.000000  \n",
       "4   0shot  0.264310  0.255433  \n",
       "5   0shot  0.291246  0.152862  \n",
       "6   5shot  0.275253  0.128456  \n",
       "7   5shot  0.253788  0.227074  \n",
       "8   0shot  0.248052 -1.000000  \n",
       "9   0shot  0.267179 -1.000000  \n",
       "10  5shot  0.282562 -1.000000  \n",
       "11  5shot  0.248558 -1.000000  \n",
       "12  0shot  0.572144  0.236136  \n",
       "13  0shot  0.812625  0.769420  \n",
       "14  5shot  0.553106  0.688112  \n",
       "15  5shot  0.511022  0.016129  \n",
       "16  0shot  0.496448  0.347721  \n",
       "17  0shot  0.498027  0.494421  \n",
       "18  0shot  0.247660  0.099783  \n",
       "19  0shot  0.265385  0.145365  \n",
       "20  5shot  0.265385  0.145365  \n",
       "21  5shot  0.247660  0.099783  \n",
       "22  0shot  0.313973  0.180325  \n",
       "23  0shot  0.361111  0.218348  \n",
       "24  5shot  0.255471  0.097614  \n",
       "25  5shot  0.250421  0.221121  \n",
       "26  0shot  0.269625  0.115558  \n",
       "27  0shot  0.290956  0.180217  \n",
       "28  5shot  0.266212  0.127336  \n",
       "29  5shot  0.261092  0.084548  \n",
       "30  0shot  0.247959  0.101346  \n",
       "31  0shot  0.267576  0.161672  \n",
       "32  5shot  0.267576  0.161672  \n",
       "33  5shot  0.247959  0.101346  \n",
       "34  0shot  0.442202  0.526234  \n",
       "35  0shot  0.378899  0.549168  \n",
       "36  5shot  0.378287  0.548724  \n",
       "37  5shot  0.377982  0.548401  \n",
       "38  0shot  0.512249  0.661515  \n",
       "39  0shot  0.492205  0.659701  \n",
       "40  5shot  0.494432  0.661699  \n",
       "41  5shot  0.496659  0.662687  \n",
       "42  0shot  0.602897  0.714747  \n",
       "43  0shot  0.721778  0.764283  \n",
       "44  5shot  0.501998  0.661919  \n",
       "45  5shot  0.497003  0.661057  \n",
       "46  0shot  0.420795  0.539173  \n",
       "47  0shot  0.378287  0.548924  \n",
       "48  5shot  0.378287  0.548724  \n",
       "49  5shot  0.378899  0.548767  \n",
       "50  0shot  0.333533  0.167115  \n",
       "51  0shot  0.333333  0.166667  \n",
       "52  5shot  0.333134  0.167039  \n",
       "53  5shot  0.331337  0.224210  \n",
       "54  0shot  0.283276  0.156770  \n",
       "55  0shot  0.317406  0.202435  \n",
       "56  5shot  0.260239  0.116684  \n",
       "57  5shot  0.261092  0.090591  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# RESULTS = Path(\"results\")\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self, accuracy, precision, recall, f1):\n",
    "        self.accuracy = accuracy\n",
    "        self.precision = precision\n",
    "        self.recall = recall\n",
    "        self.f1 = f1\n",
    "    \n",
    "    @classmethod\n",
    "    def from_json(cls, json_file):\n",
    "        with open(json_file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            return cls(\n",
    "                accuracy=data[\"accuracy\"] if data.get(\"accuracy\", None) is not None else data.get(\"average_acc\"),\n",
    "                precision=data[\"precision\"] if data.get(\"precision\", None) is not None else -1,\n",
    "                recall=data[\"recall\"] if data.get(\"recall\", None) is not None else -1,\n",
    "                f1=data[\"f1\"] if data.get(\"f1\", None) is not None else -1\n",
    "            )\n",
    "\n",
    "# Define the results directory\n",
    "results_dir = Path(\"results\")\n",
    "\n",
    "# Create a dictionary to store the results\n",
    "results_data = {\n",
    "    \"challenge\": [],\n",
    "    \"model\": [],\n",
    "    \"shot\": [],\n",
    "    \"accuracy\": [],\n",
    "    # \"precision\": [],\n",
    "    # \"recall\": [],\n",
    "    \"f1\": [],\n",
    "}\n",
    "\n",
    "# Loop through each challenge directory\n",
    "for challenge_dir in results_dir.iterdir():\n",
    "    if challenge_dir.is_dir():\n",
    "        challenge_name = challenge_dir.name\n",
    "        # Loop through each model directory within the challenge directory\n",
    "        for model_dir in challenge_dir.iterdir():\n",
    "            if model_dir.is_dir():\n",
    "                model_name = model_dir.name\n",
    "                # Read metrics.json file\n",
    "                metrics_file = model_dir / \"metrics.json\"\n",
    "                if metrics_file.exists():\n",
    "                    metrics = Metrics.from_json(metrics_file)\n",
    "                    # Append data to results dictionary\n",
    "                    results_data[\"challenge\"].append(challenge_name)    \n",
    "                    results_data[\"model\"].append(model_name.replace(\"-awq-4\", \"-4bit-quantized\")[:-6]) # when displaying shots a unique column\n",
    "                    # results_data[\"model\"].append(model_name.replace(\"-awq-4\", \"-4bit-quantized\")) # when not displaying shots\n",
    "                    results_data[\"shot\"].append(model_name[-5:])\n",
    "                    results_data[\"accuracy\"].append(metrics.accuracy)\n",
    "                    # results_data[\"precision\"].append(metrics.precision)\n",
    "                    # results_data[\"recall\"].append(metrics.recall)\n",
    "                    results_data[\"f1\"].append(metrics.f1)\n",
    "\n",
    "# Create DataFrame from results dictionary\n",
    "results_df = pd.DataFrame(results_data)\n",
    "\n",
    "# Print the DataFrame\n",
    "# print(results_df)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Grouped by: ('arc-challenge', '0shot')\n",
      "\n",
      "    challenge                                                    model  shot  accuracy       f1\n",
      "arc-challenge OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.283276 0.156770\n",
      "arc-challenge OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.317406 0.202435\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('arc-challenge', '5shot')\n",
      "\n",
      "    challenge                                                    model  shot  accuracy       f1\n",
      "arc-challenge OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.260239 0.116684\n",
      "arc-challenge OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.261092 0.090591\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('arc-challenge-hi', '0shot')\n",
      "\n",
      "       challenge                                                    model  shot  accuracy       f1\n",
      "arc-challenge-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.269625 0.115558\n",
      "arc-challenge-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.290956 0.180217\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('arc-challenge-hi', '5shot')\n",
      "\n",
      "       challenge                                                    model  shot  accuracy       f1\n",
      "arc-challenge-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.266212 0.127336\n",
      "arc-challenge-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.261092 0.084548\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('arc-easy', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      " arc-easy OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.313973 0.180325\n",
      " arc-easy OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.361111 0.218348\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('arc-easy', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      " arc-easy OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.255471 0.097614\n",
      " arc-easy OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.250421 0.221121\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('arc-easy-hi', '0shot')\n",
      "\n",
      "  challenge                                                    model  shot  accuracy       f1\n",
      "arc-easy-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.264310 0.255433\n",
      "arc-easy-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.291246 0.152862\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('arc-easy-hi', '5shot')\n",
      "\n",
      "  challenge                                                    model  shot  accuracy       f1\n",
      "arc-easy-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.275253 0.128456\n",
      "arc-easy-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.253788 0.227074\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('boolq', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "    boolq OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.420795 0.539173\n",
      "    boolq OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.378287 0.548924\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('boolq', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "    boolq OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.378287 0.548724\n",
      "    boolq OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.378899 0.548767\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('boolq-hi', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      " boolq-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.442202 0.526234\n",
      " boolq-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.378899 0.549168\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('boolq-hi', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      " boolq-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.378287 0.548724\n",
      " boolq-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.377982 0.548401\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('hellaswag', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "hellaswag OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.247660 0.099783\n",
      "hellaswag OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.265385 0.145365\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('hellaswag', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "hellaswag OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.265385 0.145365\n",
      "hellaswag OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.247660 0.099783\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('hellaswag-hi', '0shot')\n",
      "\n",
      "   challenge                                                    model  shot  accuracy       f1\n",
      "hellaswag-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.247959 0.101346\n",
      "hellaswag-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.267576 0.161672\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('hellaswag-hi', '5shot')\n",
      "\n",
      "   challenge                                                    model  shot  accuracy       f1\n",
      "hellaswag-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.267576 0.161672\n",
      "hellaswag-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.247959 0.101346\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indiccopa', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "indiccopa OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.512249 0.661515\n",
      "indiccopa OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.492205 0.659701\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indiccopa', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "indiccopa OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.494432 0.661699\n",
      "indiccopa OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.496659 0.662687\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indicsentiment', '0shot')\n",
      "\n",
      "     challenge                                                    model  shot  accuracy       f1\n",
      "indicsentiment OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.572144 0.236136\n",
      "indicsentiment OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.812625 0.769420\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indicsentiment', '5shot')\n",
      "\n",
      "     challenge                                                    model  shot  accuracy       f1\n",
      "indicsentiment OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.553106 0.688112\n",
      "indicsentiment OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.511022 0.016129\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indicxnli', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "indicxnli OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.333533 0.167115\n",
      "indicxnli OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.333333 0.166667\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indicxnli', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy       f1\n",
      "indicxnli OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.333134 0.167039\n",
      "indicxnli OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.331337 0.224210\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indicxparaphrase', '0shot')\n",
      "\n",
      "       challenge                                                    model  shot  accuracy       f1\n",
      "indicxparaphrase OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.602897 0.714747\n",
      "indicxparaphrase OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.721778 0.764283\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('indicxparaphrase', '5shot')\n",
      "\n",
      "       challenge                                                    model  shot  accuracy       f1\n",
      "indicxparaphrase OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.501998 0.661919\n",
      "indicxparaphrase OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.497003 0.661057\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('mmlu', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy   f1\n",
      "     mmlu OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.267626 -1.0\n",
      "     mmlu OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.312277 -1.0\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('mmlu', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy   f1\n",
      "     mmlu OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.309358 -1.0\n",
      "     mmlu OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.256374 -1.0\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('mmlu-hi', '0shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy   f1\n",
      "  mmlu-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.248052 -1.0\n",
      "  mmlu-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.267179 -1.0\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('mmlu-hi', '5shot')\n",
      "\n",
      "challenge                                                    model  shot  accuracy   f1\n",
      "  mmlu-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 5shot  0.282562 -1.0\n",
      "  mmlu-hi OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 5shot  0.248558 -1.0\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Grouped by: ('winogrande', '0shot')\n",
      "\n",
      " challenge                                                    model  shot  accuracy       f1\n",
      "winogrande OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-chat-format 0shot  0.496448 0.347721\n",
      "winogrande OpenHathi-7B-Hi-v0.1-Base-LoRA-samvaad-hi-v1-tulu-format 0shot  0.498027 0.494421\n",
      "==================================================================================================== \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouping the DataFrame by challenge\n",
    "\n",
    "grouped_df = results_df.groupby(by=[\"challenge\", \"shot\"])\n",
    "# Printing a nice representation of the grouped DataFrame\n",
    "for model_key, group in grouped_df:\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Grouped by: {model_key}\\n\")\n",
    "    print(group.to_string(index=False))\n",
    "    print(\"=\" * 100, \"\\n\" * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
